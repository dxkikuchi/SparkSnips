def set_hadoop_config(credentials):
   prefix = "fs.swift.service." + credentials['name'] 
   hconf = sc._jsc.hadoopConfiguration()
   hconf.set(prefix + ".auth.url", credentials['auth_url']+'/v3/auth/tokens')
   hconf.set(prefix + ".auth.endpoint.prefix", "endpoints")
   hconf.set(prefix + ".tenant", credentials['project_id'])
   hconf.set(prefix + ".username", credentials['user_id'])
   hconf.set(prefix + ".password", credentials['password'])
   hconf.setInt(prefix + ".http.port", 8080)
   hconf.set(prefix + ".region", credentials['region'])
   hconf.setBoolean(prefix + ".public", True)
credentials = {}
credentials['name'] = 'spark'
credentials['auth_url'] = '<yourAuthURL>'
credentials['project_id'] = '<yourProjectID>'
credentials['region'] = '<yourRegion>'
credentials['user_id'] = '<yourUserID>'
credentials['password'] = '<yourPassword>'
set_hadoop_config(credentials)
<yourRDD> = sc.textFile("swift://<yourObjectStoreContainer>.spark/<yourFiles>")
<yourRDD>.take(3)
